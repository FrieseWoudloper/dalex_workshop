---
title: "DALEX"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
description: "Learn to explore and explain supervised machine learning models with DALEX."
---

```{r setup, include=FALSE, message=FALSE, results='hide'}
library(learnr)
library(gradethis)
library(DALEX)
library(ranger)
library(rms)

knitr::opts_chunk$set(echo = FALSE, exercise.checker = gradethis::grade_learnr)

set.seed(1313)
titanic_rf <- ranger(survived ~ ., data = titanic_imputed,
                          classification = TRUE, probability = TRUE)
exp_rf <- explain(titanic_rf,
                      data = titanic_imputed[, 1:7],
                      y = titanic_imputed$survived,
                      label = "Random Forest")
mp_rf <- model_performance(exp_rf)

titanic_lms <- lrm(survived ~ rcs(age)*gender + rcs(fare) + class,
                   data = titanic_imputed)
exp_lms <- explain(titanic_lms,
                   data = titanic_imputed,
                   y = titanic_imputed$survived,
                   label = "Logistic with splines")
mp_lms <- model_performance(exp_lms)
```

## Welcome

This tutorial will teach you how to explore and explain model behavior using the [DALEX](https://modeloriented.github.io/DALEX/) package.

### Learning objectives

The tutorial focuses on explainability of classification models. 

We will cover:    

+ How to create an _explainer_ for a model
+ How to create an explanation for the overall behavior of a model (_global explanation_)
+ How to create an explanation for individual predictions (_local explanation_)
+ How to compare explanations for different kind of models
+ How to visualize the trade-off between accuracy and explainability

We will only be using _model-agnostic_ methods. These methods treat machine learning models as black boxes. They do not need access to model internals. They work by changing the input of the model and measuring changes in the prediction output.

### Pre-requisites 
We assume you have basic knowledge of training and evaluating machine learning models in R.

Let's get started!

## Titanic dataset
For the next exercises we will use the `titanic_imputed` dataset. It is a list of people who were on board the Titanic when it sank. Run `?DALEX::titanic_imputed` in R for detail information about the dataset.

To see the first six rows of the dataset click on **Run Code**.   

```{r data-titanic, exercise=TRUE, exercise.eval=FALSE, exercise.lines=3}
head(titanic_imputed)
```

The variable `survived` specifies whether the person has survived the sinking: Yes (1) or No (0).

In the next steps we will create and explain a model that predicts whether a person will survive.

## Model & explainer

### Create a random forest model
Insert the name of the target variable in the code chunk and run the code to train a Random Forest model. You can click on the **Solution** button to get help.

```{r rf-titanic, exercise=TRUE, warning=FALSE, message=FALSE, error=FALSE}
library(ranger)
set.seed(1313)
titanic_rf <- ranger(___ ~ ., data = titanic_imputed,
                     classification = TRUE, probability = TRUE)
titanic_rf
```

```{r rf-titanic-solution}
library(ranger)
titanic_rf <- ranger(survived ~ ., data = titanic_imputed,
                     classification = TRUE, probability = TRUE)
titanic_rf
```

### Create an explainer

Create a model explainer using the `explain` function from the `DALEX` package.

The first argument to the function is the model you want to explain. It is the model you created in the previous step. The second argument is the data frame with the features, and the third a numeric vector with the true outcome of the target variable. The last one is the name of the model. It can be anything you like.

```{r explain-rf-titanic, exercise=TRUE, warning=FALSE, message=FALSE, error=FALSE}
library(DALEX)
exp_rf <- explain(___,
                  data = titanic_imputed[, 1:7],
                  y = ___$survived,
                  label = "Random Forest")
```

```{r explain-rf-titanic-solution}
library(DALEX)
exp_rf <- explain(titanic_rf,
                  data = titanic_imputed[, 1:7],
                  y = titanic_imputed$survived,
                  label = "Random Forest")
```

After the explainer is created, you can use it to request base information about the model.

```{r rf-model-info-titanic, exercise=TRUE, exercise.eval=FALSE, exercise.lines=3}
exp_rf$model_info
```

HIER NOG WAT TUSSEN OVER DE STRUCTUUR VAN HET EXPLAINER OBJECT?

Change this code chunk so it no longer returns the true outcomes, but the predicted probabilities. 

```{r rf-preds-titanic, exercise=TRUE, exercise.eval=FALSE}
head(exp_rf$y)
```

```{r rf-preds-titanic-solution}
head(exp_rf$y_hat)
```

### Create another model with accompanying explainer

Let's also train a logistic regression model with splines, so we can choose the best model. Again create an explainer, so we can later on compare the two models not only on accuracy, but also explainability.

```{r rms-titanic, exercise=TRUE, exercise.eval=FALSE, exercise.lines=9}
library(rms)
titanic_lms <- lrm(survived ~ rcs(age)*gender + rcs(fare) + class,
                   data = titanic_imputed)
exp_lms <- explain(___,
                   data = ___,
                   y = ___,
                   label = "Logistic with splines")
```

```{r rms-titanic-solution}
library(rms)
set.seed(123)
titanic_lms <- lrm(survived ~ rcs(age)*gender + rcs(fare) + class,
                   data = titanic_imputed)
exp_lms <- explain(titanic_lms,
                   data = titanic_imputed,
                   y = titanic_imputed$survived,
                   label = "Logistic with splines")
```

Extract the model base information from the explainer.

```{r rms-model-info-titanic, exercise=TRUE, exercise.eval=FALSE, exercise.lines=3}
exp_lms$___
```

```{r rms-model-info-titanic-solution}
exp_lms$model_info
```

## Model performance

Let's see how both models perform on the training set using the `model_performance` function. Of course, you should evaluate performance on a testing dataset. However, to keep this tutorial simple, we'll skip that part for now.

```{r mp-rf-titanic, exercise=TRUE, exercise.eval=TRUE, exercise.lines=3}
model_performance(exp_rf)
```

<div id="mp-rf-titanic-hint">
**Hint:** You may want to compare the output of `model_performance(exp_rf)` to `model_performance(exp_lms)`.
</div>

```{r mp-titanic, echo=FALSE}
question("Which model we trained in the previous section seems to perform better?",
  answer("Random forest model", correct = TRUE),
  answer("Logistic model with splines"),
  answer("Both models perform equally")
)
```

We can visualize and compare model performance using the `plot` function. By providing an `geom` argument we can specify how we want to summarize residuals. Valid values are `"prc"`, `"roc"`, `"ecdf"`, `"boxplot"`, `"gain"`, `"lift"` and `"histogram"`.

Adjust the code below so that an _Receiver Operator Characteristic_ (ROC) curve is created, and we can verify that the random forest model has a larger _Area Under the Curve_ (AUC) and thus performs better.

```{r roc-titanic, exercise=TRUE, exercise.eval=TRUE}
mp_rf <- model_performance(exp_rf)
mp_lms <- model_performance(exp_lms)
plot(mp_rf, mp_lms, geom = "prc")
```

```{r roc-titanic-solution}
mp_rf <- model_performance(exp_rf)
mp_lms <- model_performance(exp_lms)
plot(mp_rf, mp_lms, geom = "roc")
```

### Explain individual predictions



