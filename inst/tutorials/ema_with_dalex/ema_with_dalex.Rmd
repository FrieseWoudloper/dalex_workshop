---
title: "DALEX"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
    number_sections: true
runtime: shiny_prerendered
description: "Learn to explore, explain and examine predictive models with DALEX."
---

```{r setup, include=FALSE, message=FALSE}
library(learnr)
library(DALEX)
library(ranger)
library(rms)

knitr::opts_chunk$set(echo = FALSE)
 
# Train en test
set.seed(1234)
index <- sample(1:nrow(titanic_imputed), 
                as.integer(nrow(titanic_imputed) * .80), 
                replace = FALSE)
train <- titanic_imputed[index,]
test <- titanic_imputed[-index,]

# Train models
titanic_lms <- lrm(survived ~ rcs(age)*gender + rcs(fare) + class,
                   data = train)
set.seed(1234)
titanic_rf <- ranger(survived ~ ., data = train,
                     classification = TRUE, probability = TRUE)

# Create explainer objects
exp_lms <- explain(titanic_lms,
                   data = train,
                   y = train$survived,
                   label = "Logistic with splines")
exp_rf <- explain(titanic_rf,
                  data = train[, 1:7],
                  y = train$survived,
                  label = "Random Forest")

# Create model performance object
mp_rf <- model_performance(exp_rf)
mp_lms <- model_performance(exp_lms)

# joe <- titanic_imputed[1,]
# johnny_d <- data.frame(
#           class = factor("1st", levels = c("1st", "2nd", "3rd", 
#                      "deck crew", "engineering crew", 
#                      "restaurant staff", "victualling crew")),
#           gender = factor("male", levels = c("female", "male")),
#           age = 8, sibsp = 0, parch = 0, fare = 72,
#           embarked = factor("Southampton", levels = c("Belfast",
#                       "Cherbourg","Queenstown","Southampton")))
# 
# lucy <- data.frame(
#       class = factor("1st", levels = c("1st", "2nd", "3rd", 
#                      "deck crew", "engineering crew", 
#                      "restaurant staff", "victualling crew")),
#       gender = factor("female", levels = c("female", "male")),
#       age = 18, sibsp = 0, parch = 0, fare = 70,
#       embarked = factor("Southampton", levels = c("Belfast",
#                         "Cherbourg","Queenstown","Southampton")))
# 
# bd_joe <- predict_parts(exp_rf, joe, type = "break_down_interactions")
# bd_lucy <- predict_parts(exp_rf, lucy, type = "break_down_interactions")
# sh_joe_rf <- predict_parts(exp_rf, joe, type = "shap")
# sh_joe_lms <- predict_parts(exp_lms, joe, type = "shap")
```

## Welcome

This tutorial will teach you how to explore, explain and examine predictive models using the [DALEX](https://modeloriented.github.io/DALEX/) package in R. DALEX is short for mo<b>D</b>el <b>A</b>gnostic <b>L</b>anguage for <b>E</b>xploration and e<b>X</b>planation.

### Learning objectives

We will cover:    

+ How to create an _explainer_ for a model
+ How to examine model accuracy 
+ How to create an explanation for the overall behavior of a model (_dataset level_)
+ How to create an explanation for individual predictions (_instance level_)
+ How to compare models with regard to explainability

We will only use _model-agnostic_ methods. These methods treat machine learning models as black boxes. They do not need access to model internals. They work by changing the input of the model and measuring changes in the prediction output.

The tutorial focuses solely on explainability of classification models. However, DALEX can just as easily be used to explain regression models.

This tutorial is based on the book [Explanatory Model Analysis](https://pbiecek.github.io/ema/) by Przemyslaw Biecek and Tomasz Burzykowski. It is a great resource and highly recommended. 

### Pre-requisites 
We assume you have basic knowledge of training and evaluating machine learning models in R.

Let's get started!

## Titanic dataset
For the exercises we will use the `titanic_imputed` dataset. It is a list of people who were on board the Titanic when it sank. Run `?DALEX::titanic_imputed` in R for detail information about the dataset.

In the next steps we will create different kind of models that predict whether a person will survive. That is why we split the dataset into a training and test set.

Click on **Run Code** to create the training and test set, and see the first six rows of the training set.   

```{r ex1, exercise=TRUE, exercise.eval=FALSE}
index <- sample(1:nrow(titanic_imputed), 
                as.integer(nrow(titanic_imputed) * .80), 
                replace = FALSE)
train <- titanic_imputed[index,]
test <- titanic_imputed[-index,]
head(train)
```

`survived` is the target variable. It specifies whether the person has survived the sinking: Yes (1) or No (0).

## Model

### Logistic regression model

First we train a logistic regression model with splines. Click on **Run Code**.

```{r ex2, exercise=TRUE, warning=FALSE, message=FALSE, error=FALSE}
library(rms)
titanic_lms <- lrm(survived ~ rcs(age)*gender + rcs(fare) + class, 
                   data = train)
titanic_lms
```

### Random forest model

We also train a random forest model, so we can later on choose the best model. Insert the name of the target variable in the code chunk and run the code. You can click on the **Solution** button to get help.

```{r ex3, exercise=TRUE, warning=FALSE, message=FALSE, error=FALSE}
library(ranger)
set.seed(1234)
titanic_rf <- ranger(___ ~ ., 
                     data = train, 
                     classification = TRUE, 
                     probability = TRUE)
titanic_rf
```

```{r ex3-solution}
library(ranger)
set.seed(1234)
titanic_rf <- ranger(survived ~ ., 
                     data = train, 
                     classification = TRUE, 
                     probability = TRUE)
titanic_rf
```

## Explainer

### Explainer for the logistic regression model

In the previous step we created two models. They have different internal structures and interfaces. We need a uniform interface in order to create explanations and compare both models. For this purpose we create model explainer objects.

We do that with the help of the `explain()` function from the `DALEX` package. The first and required argument to the function is the model to be explained. The `data` argument specifies a data frame with features and `y` a numeric vector with true outcomes. `label` contains the name of the model. It can be anything you like.

```{r ex4, exercise=TRUE, warning=FALSE, message=FALSE, error=FALSE}
library(DALEX)
exp_lms <- explain(___,
                   data = train[, 1:7],
                   y = ___$survived,
                   label = "Logistic with splines")
```

```{r ex4-solution}
library(DALEX)
exp_lms <- explain(titanic_lms,
                   data = train,
                   y = train$survived,
                   label = "Logistic with splines")
```

After the explainer has been created, you can retrieve basic information about the model.

```{r ex5, exercise=TRUE, exercise.eval=FALSE}
exp_lms$model_info
```

### Explainer for the random forest model

Now also create an explainer for the random forest model.

```{r ex6, exercise=TRUE, exercise.eval=FALSE, warning=FALSE, message=FALSE, error=FALSE}

exp_rf <- explain(___,
                  data = ___,
                  y = ___,
                  label = "Random forest")
```

```{r ex6-solution}
library(DALEX)
exp_rf <- explain(titanic_rf,
                  data = train[, 1:7],
                  y = train$survived,
                  label = "Random forest")
```

Extract model information from the explainer.

```{r ex7, exercise=TRUE, exercise.eval=FALSE, warning=FALSE, message=FALSE, error=FALSE}

```

```{r ex7-solution}
exp_rf$model_info
```

```{r q1, echo=FALSE}
l <- unlist(strsplit(exp_rf$model_info$ver, "[.]"))
create_answer <- function(){
  index <- sample(1:3, 1)
  l[index] <<- as.character(as.integer(l[index]) + 1)
  return(paste(l, collapse = "."))
}
question("What version of the <code>ranger</code> package was used to create the model?",
  answer(create_answer()),
  answer(exp_rf$model_info$ver, correct = TRUE),  
  answer(create_answer()),
  answer(create_answer())
)
```

<!-- ## Model performance -->

<!-- Let's see how both models perform on the training set using the `model_performance()` function. Of course you should also evaluate performance on a testing dataset. However, to keep this tutorial simple, we'll skip that part for now. -->

<!-- ```{r mp-rf-titanic, exercise=TRUE, exercise.eval=TRUE, exercise.lines=3} -->
<!-- model_performance(exp_rf) -->
<!-- ``` -->

<!-- <div id="mp-rf-titanic-hint"> -->
<!-- **Hint:** You may want to compare the output of `model_performance(exp_rf)` to `model_performance(exp_lms)`. -->
<!-- </div> -->

<!-- ```{r mp-titanic, echo=FALSE} -->
<!-- question("Which model we trained in the previous section seems to perform better?", -->
<!--   answer("Random forest model", correct = TRUE), -->
<!--   answer("Logistic regression model with splines"), -->
<!--   answer("Both models perform equally") -->
<!-- ) -->
<!-- ``` -->

<!-- We can visualize and compare model performance using the `plot` function. By providing an `geom` argument we can specify how we want to summarize residuals. Valid values are `"prc"`, `"roc"`, `"ecdf"`, `"boxplot"`, `"gain"`, `"lift"` and `"histogram"`. -->

<!-- Adjust the code below so that an _Receiver Operator Characteristic_ (ROC) curve is created, and we can verify that the random forest model has a larger _Area Under the Curve_ (AUC) and thus performs better. -->

<!-- ```{r roc-titanic, exercise=TRUE, exercise.eval=TRUE} -->
<!-- mp_rf <- model_performance(exp_rf) -->
<!-- mp_lms <- model_performance(exp_lms) -->
<!-- plot(mp_rf, mp_lms, geom = "prc") -->
<!-- ``` -->

<!-- ```{r roc-titanic-solution} -->
<!-- mp_rf <- model_performance(exp_rf) -->
<!-- mp_lms <- model_performance(exp_lms) -->
<!-- plot(mp_rf, mp_lms, geom = "roc") -->
<!-- ``` -->

<!-- ## Explanations for overall model behavior -->

<!-- ## Explanations for predictions -->

<!-- ### Make predictions -->

<!-- Let us now compare predictions that are obtained from the two different models. In particular, we compute the predicted probability of survival for Joe. -->

<!-- Joe is a 42-year-old male who embarked in Southampton and travels third class with no parents nor siblings, and with a ticket costing a little over 7 pounds. -->

<!-- ```{r henry-titanic, exercise=TRUE, exercise.eval=FALSE} -->
<!-- joe <- titanic_imputed[1,] -->
<!-- joe -->
<!-- ``` -->

<!-- First predict the probability of Joe surviving using the random forest model. -->

<!-- ```{r pred-joe-titanic, exercise=TRUE, exercise.eval=TRUE} -->
<!-- predict(exp_rf, joe) -->
<!-- ``` -->

<div id="pred-joe-titanic-hint">
**Hint:** You probably want to compare the output of `predict(exp_rf, joe)` to `predict(exp_lms, joe)`.
</div>

We can also predict survival using the logistic regression model.

```{r joe-titanic, echo=FALSE}
question("Which model predicts a slightly higher probability of survival for Joe?",
  answer("Random forest model", correct = TRUE),
  answer("Logistic regression model with splines")
)
```

<!-- ### Create break-down plots  -->

<!-- Both our models predict that it is not very likely that Joe will survive the sinking of the Titanic. Which characteristics of Joe were of most importance here? One way of answering this question is by creating a _break-down plot for additive attributions_. The plot is a decomposition of the model's prediction into contributions that can be attributed to different explanatory variables. -->

<!-- ```{r bd-joe-titanic, exercise=TRUE, exercise.eval=TRUE} -->
<!-- bd_joe <- predict_parts(exp_rf, joe, type = "break_down_interactions") -->
<!-- plot(bd_joe) -->
<!-- ``` -->

<!-- From the break-down profile we can see, that the fact that Joe is a man decreases his chances of survival significantly. -->

<!-- Another passenger aboard the Titanic is Lucy. She is a 18-year-old girl who also embarked in Southampton and travels first class without parents nor siblings. Her ticket costs 70 pounds. A dataframe containing Lucy's characteristics has already been created for our convenience. -->

<!-- ```{r pred-lucy-titanic, exercise=TRUE, exercise.eval=TRUE} -->
<!-- predict(exp_rf, lucy) -->
<!-- ``` -->

<!-- ```{r pred-lucy-titanic-solution} -->
<!-- bd_lucy <- predict_parts(exp_rf, lucy, type = "break_down_interactions") -->
<!-- plot(bd_lucy) -->
<!-- ``` -->

<!-- Our random forest model predicts that Lucy will very likely survive. Now let's answer the following question using this model and a break-down plot. Add some code to the chunk above to get the right answer. -->

<!-- ```{r lucy-titanic, echo=FALSE} -->
<!-- question("Which three characteristics of Lucy have the biggest <u>positive</u> contribution to her predicted survival?", -->
<!--   answer("age = 18"), -->
<!--   answer("class = 1st", correct = TRUE),   -->
<!--   answer("embarked = Southampton"), -->
<!--   answer("fare = 70", correct = TRUE), -->
<!--   answer("gender = female", correct = TRUE), -->
<!--   answer("number of siblings aboard = 0"), -->
<!--   answer("number of parents aboard = 0") -->
<!-- ) -->
<!-- ``` -->

<!-- ### Important issue with break-down plots -->

<!-- Break-down plots are easy to understand, and they are compact. However, they can also be misleading. This is the case for models including interactions. Break-down plots only show the additive attributions. Thus the choice of the ordering of the explanatory variables in the calculation of the variable-importance measures is important. Let's illustrate this with an example. -->

<!-- ```{r bd-order-titanic, exercise=TRUE, exercise.eval=TRUE} -->
<!-- bd_lucy_order <- predict_parts(exp_rf, lucy,  -->
<!--                                order = c("age", "gender", "fare", "class", -->
<!--                                          "parch", "sibsp", "embarked")) -->
<!-- plot(bd_lucy_order) -->
<!-- ``` -->

<!-- We can see that fare&nbsp;=&nbsp;70 now has a <u>negative</u> contribution to the prediction, and that the positive contribution of class&nbsp;=&nbsp;1st has significantly increased! -->

<!-- There are several ways of addressing the issue of the dependence of the variable-importance measure on the ordering of the explanatory variables. One approach is using SHAP, as we will see in the next section. -->

<!-- ### Create SHapley Additive exPlanations -->

<!-- Another way to explain individual predictions is by creating _SHapley Additive exPlanations_ (SHAP).  -->

<!-- Let's start by visualizing SHAP values for the random forest model's prediction for Joe. -->

<!-- ```{r sh-joe-rf-titanic, exercise=TRUE, exercise.eval=TRUE} -->
<!-- sh_joe_rf <- predict_parts(exp_rf, joe, type = "shap") -->
<!-- plot(sh_joe_rf, show_boxplots = FALSE) -->
<!-- ``` -->

<!-- Now also visualize Joe's SHAP values based upon the logistic regression model, so we can compare not only the predictions, but also the explanations of the two different models. -->

<!-- ```{r sh-joe-lms-titanic, exercise=TRUE, exercise.eval=FALSE, warning=FALSE, message=FALSE, error=FALSE} -->
<!-- sh_joe_lms <- predict_parts(___, joe, type = "shap") -->
<!-- plot(___, show_boxplots = FALSE) -->
<!-- ``` -->

<!-- ```{r sh-joe-lms-titanic-solution} -->
<!-- sh_joe_lms <- predict_parts(exp_lms, joe, type = "shap") -->
<!-- plot(sh_joe_lms, show_boxplots = FALSE) -->
<!-- ``` -->

<!-- What are the most striking differences between the explanations for Joe's prediction for the two different models? -->

### Ceteris-paribus

