---
title: "DALEX"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
description: "Learn to explore, explain and examine classification models with DALEX using the Titanic dataset."
---

```{r setup, include=FALSE, message=FALSE}
library(learnr)
library(archivist)
library(DALEX)
library(rms)
library(randomForest)
library(gbm)
library(e1071)

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, error = FALSE)

# Data
titanic  <- archivist::aread("pbiecek/models/27e5c")
johnny_d <- archivist::aread("pbiecek/models/e3596")
henry    <- archivist::aread("pbiecek/models/a6538")
 
# Train models
titanic_lrm <- archivist::aread("pbiecek/models/58b24")
titanic_rf  <- archivist::aread("pbiecek/models/4e0fc")
titanic_gbm <- archivist::aread("pbiecek/models/b7078")
titanic_svm <- archivist::aread("pbiecek/models/9c27f")

# Create explainer objects
titanic_lrm_exp <- explain(titanic_lrm,
                           data = titanic[, -9],
                           y = titanic$survived == "yes",
                           label = "Logistic Regression",
                           type = "classification",
                           verbose = FALSE)
titanic_rf_exp <- explain(model = titanic_rf, 
                       data = titanic[, -9],
                       y = titanic$survived == "yes", 
                       label = "Random Forest",
                       verbose = FALSE)
titanic_gbm_exp <- explain(model = titanic_gbm, 
                       data = titanic[, -9],
                       y = titanic$survived == "yes", 
                       label = "Generalized Boosted Regression",
                       verbose = FALSE)
titanic_svm_exp <- explain(model = titanic_svm, 
                       data = titanic[, -9],
                       y = titanic$survived == "yes", 
                       label = "Support Vector Machine",
                       verbose = FALSE)
# 
# # Create model performance object
# mp_lms <- model_performance(exp_lms)
# mp_rf <- model_performance(exp_rf)
# 
# # Instances
# joe <- titanic_imputed[1,]
# lucy <- data.frame(
#       class = factor("1st", levels = c("1st", "2nd", "3rd",
#                      "deck crew", "engineering crew",
#                      "restaurant staff", "victualling crew")),
#       gender = factor("female", levels = c("female", "male")),
#       age = 18, sibsp = 0, parch = 0, fare = 70,
#       embarked = factor("Southampton", levels = c("Belfast",
#                         "Cherbourg","Queenstown","Southampton")))
# 
# bd_joe <- predict_parts(exp_rf, joe, type = "break_down_interactions")
# bd_lucy <- predict_parts(exp_rf, lucy, type = "break_down_interactions")
# sh_joe_rf <- predict_parts(exp_rf, joe, type = "shap")
# sh_joe_lms <- predict_parts(exp_lms, joe, type = "shap")
```

## 1 Welcome

This tutorial will teach you how to explore, explain and examine predictive models using the [DALEX](https://modeloriented.github.io/DALEX/) package in R. DALEX is short for mo<b>D</b>el <b>A</b>gnostic <b>L</b>anguage for <b>E</b>xploration and e<b>X</b>planation.

### 1.1 Learning objectives

We will cover:    

+ How to obtain insight into the overall behavior of a model.
+ How to obtain insight into a model's prediction for a single observation.
+ How to examine model performance and understanding the weaknesses.

We will only use _model-agnostic_ methods. These methods treat machine learning models as black boxes. They do not need access to model internals. They work by changing the input of the model and measuring changes in the prediction output.

This tutorial focuses solely on explainability of classification models. However, DALEX can just as easily be used to explain regression models.

This tutorial is based on the book [Explanatory Model Analysis](https://pbiecek.github.io/ema/) by Przemyslaw Biecek and Tomasz Burzykowski. It is a great resource and highly recommended. You can read it for free online. The book will also be available in print from early 2021.

### 1.2 Pre-requisites 
We assume you have basic knowledge of R, specifically of training machine learning models.

Let's get started!

## 2 Titanic dataset
We will use the `titanic` dataset. It contains the details of a subset of persons aboard the Titanic when it sank: 

* *gender*, the person's gender;
* *age*, the person's age in years; 
* *class*, the class in which the passenger travelled, or the duty class of a crew member;
* *embarked*, the harbor in which the person embarked on the ship;
* *country*, person’s home country;
* *fare*, the price of the ticket;
* *sibsp*, the number of siblings/spouses aboard the ship;
* *parch*, the number of parents/children aboard the ship;
* *survived*, the person's survival of the disaster, _yes_ or _no_.

Click **Run Code** to see the first six rows of the dataset.   

```{r ex1, exercise = TRUE}
head(titanic)
```

In the next steps of this tutorial we will create two different kind of models. They both predict the probability of survival aboard the Titanic. So `survived` is the dependent variable. 

## 3 Models

### 3.1 Logistic regression model

It makes sense to start with a logistic regression model. We use restricted cubic splines to model the non-linear effect of age on the odds of survival.     

Click **Run Code** to train the model.

```{r ex2, exercise = TRUE}
library(rms)
titanic_lrm <- lrm(survived == "yes" ~ class + gender + rcs(age) + sibsp + parch + fare + embarked, 
                   data = titanic)
cat("The logistic regression model has been created.")
```

The logistic model is interpretable-by-design. We also create a number of so called 'black-box' models.

### 3.2 Random forest model

Our first black-box model is a random forest model. Insert the name of the dependent variable in the code chunk. Run the code. Click the **Solution** button to get help.

```{r ex3, exercise = TRUE}
library(randomForest)
set.seed(1313)
titanic_rf <- randomForest(___ ~ class + gender + age + sibsp + parch + fare + embarked, 
                           data = titanic)
cat("The random forest model has been created.")
```

```{r ex3-solution}
library(randomForest)
set.seed(1313)
titanic_rf <- randomForest(survived ~ class + gender + age + sibsp + parch + fare + embarked, 
                           data = titanic)
cat("The random forest model has been created.")
```

### 3.3 Gradient boosting model

Additionally, we create a gradient boosting model. This may take some time.

```{r ex4, exercise = TRUE, exercise.timelimit = 120}
library(gbm)
set.seed(1313)
titanic_gbm <- gbm(survived == "yes" ~ class + gender + age + sibsp + parch + fare + embarked, 
                   data = titanic, 
                   n.trees = 15000, 
                   distribution = "bernoulli")
cat("The gradient boosting model has been created.")
```

### 3.4 Support vector machine model

Finally, we also create a support vector machine (SVM) model. 

```{r ex5, exercise = TRUE}
library(e1071)
set.seed(1313)
titanic_svm <- svm(survived == "yes" ~ class + gender + age + 
                 sibsp + parch + fare + embarked, data = titanic, 
                 type = "C-classification", probability = TRUE)
cat("The support vector machine model was created.")
```


## 4 Models' predictions

Let's predict the probability of survival for two passengers aboard the Titanic: Johnny D and Henry. 

### 4.1 Johnny D

For convenience, a dataset with Johnny D's data has already been created.

```{r ex6, exercise = TRUE, exercise.eval = TRUE}
print(johnny_d)
```

As we can see, Johnny D is an 8-year-old boy who embarked in Southampton and travelled in the first class with no parents nor siblings, and with a ticket costing 72 pounds.

We obtain the predicted probability of survival for Johnny D for the different models with the generic function `predict()`.

```{r ex7, exercise = TRUE}
pred_lrm <- predict(titanic_lrm, johnny_d, type = "fitted")
pred_rf  <- predict(titanic_rf,  johnny_d, type = "prob")
pred_gbm <- predict(titanic_gbm, johnny_d, type = "response", n.trees = 15000)
pred_svm <- predict(titanic_svm, johnny_d, probability = TRUE)
cat("Predicted probability of survival for Johnny D\n",
    "==============================================\n",
    sprintf("Logistic regression model: %.*f\n", 2, pred_lrm),
    sprintf("Random forest model: %.*f\n", 2, pred_rf[1, "yes"]),    
    sprintf("Gradient boosting model: %.*f\n", 2, pred_gbm), 
    sprintf("Support vector machine model: %.*f\n", 2, attr(pred_svm, "probabilities")[1,"TRUE"]), 
    sep = "")
```

The predictions differ substantially. What causes these differences? Which model deserves our trust? Let's try and find the answers to these questions!

### 4.2 Henry

Henry is an 47-year-old man who embarked in Cherbourg and travelled in the first class with no parents nor siblings, and with a ticket costing 25 pounds.

```{r ex8, exercise = TRUE, exercise.eval = TRUE}
print(henry)
```

For Henry we also predict the odds of survival using different models.

```{r ex9, exercise = TRUE}
pred_lrm <- predict(titanic_lrm, henry, type = "fitted")
pred_rf  <- predict(titanic_rf,  henry, type = "prob")
pred_gbm <- predict(titanic_gbm, henry, type = "response", n.trees = 15000)
pred_svm <- predict(titanic_svm, henry, probability = TRUE)
cat("Predicted probability of survival for Henry\n",
    "==============================================\n",
    sprintf("Logistic regression model: %.*f\n", 2, pred_lrm),
    sprintf("Random forest model: %.*f\n", 2, pred_rf[1, "yes"]),    
    sprintf("Gradient boosting model: %.*f\n", 2, pred_gbm), 
    sprintf("Support vector machine model: %.*f\n", 2, attr(pred_svm, "probabilities")[1,"TRUE"]), 
    sep = "")
```

```{r q1}
question("How does the prediction for Henry compare to that for Johnny D?",
  answer("Henry's predicted probability of survival is <i>lower</i>.", correct = TRUE),
  answer("The predicted probabilities of survival for Henry and Johnny D are <i>equal</i>."),
  answer("Henry's predicted probability of survival is <i>higher</i>.")
)
```

## 5 Models' explainers

The models trained in the previous step have different internal structures and interfaces. We need a unified interface, so that we can easily obtain explanations and compare the models. For this purpose we create _model explainer objects_. An explainer object contains all elements needed to generate a model explanation.

We use the function `explain()` from the `DALEX` package to create an explainer object. The function arguments that we use in this tutorial are:

* `model` (required), the model to be explained;
* `data`, data to which the model is to be applied, be sure to remove the dependent variable; 
* `y`, observed values of the dependent variable corresponding to the data given in the `data` object;
* `label`, unique name of the model;
* `type`, information about the type of the model, either `"classification"` or `"regression"`,
* `verbose`, logical indicating whether diagnostic messages are to be printed.

Let's start with an explainer for the logistic regression model. Complete the code block below and run it.

```{r ex10, exercise = TRUE}
library(DALEX)
titanic_lrm_exp <- explain(model = ___,
                           data = titanic[, -9],
                           y = ___$survived == "yes",
                           label = "Logistic Regression",
                           type = ___)
```

```{r ex10-solution}
library(DALEX)
titanic_lrm_exp <- explain(model = titanic_lrm,
                           data = titanic[, -9],
                           y = titanic$survived == "yes",
                           label = "Logistic Regression",
                           type = "classification")
```

Once the explainer has been created, we can retrieve basic information about the model.

```{r ex11, exercise = TRUE}
titanic_lrm_exp$model_info
```

We also create explainer objects for the other models.

``````{r ex12, exercise = TRUE}
titanic_rf_exp <- explain(model = titanic_rf, 
                       data = titanic[, -9],
                       y = titanic$survived == "yes", 
                       label = "Random Forest",
                       verbose = FALSE)
titanic_gbm_exp <- explain(model = titanic_gbm, 
                       data = titanic[, -9],
                       y = titanic$survived == "yes", 
                       label = "Generalized Boosted Regression",
                       verbose = FALSE)
titanic_svm_exp <- explain(model = titanic_svm, 
                       data = titanic[, -9],
                       y = titanic$survived == "yes", 
                       label = "Support Vector Machine",
                       verbose = FALSE)
cat("The explainers have been created.")
```

Get the information for the support vector machine model from the appropriate explainer.

```{r ex13, exercise = TRUE}

```

```{r ex13-solution}
titanic_svm_exp$model_info
```

```{r q2}
l <- unlist(strsplit(titanic_svm_exp$model_info$ver, "[.]"))
create_answer <- function(){
  index <- sample(1:3, 1)
  l[index] <<- as.character(as.integer(l[index]) + 1)
  return(paste(l, collapse = "."))
}
question("What version of the <code>e1071</code> package was used to create the support vector machine model?",
         answer(create_answer()),
         answer(titanic_svm_exp$model_info$ver, correct = TRUE),  
         answer(create_answer()),
         answer(create_answer())
)
```

## 6 Instance level explanations

An _instance level explanation_ helps us understand the model response (prediction) at a single point (instance). Sometimes it's also called a _local explanation_. There are different approaches to instance level explanations, which we will consider in turn.

One approach is to analyze how the model’s prediction for a particular instance differs from the average prediction, and to which explanatory variables this difference can be attributed. It is often called the _variable attributions_ approach. Break-down plots and SHAP are examples of the variable attributions approach.

Another approach is to use a simpler glass-box model to approximate the black-box model around the point (instance) of interest. The glass-box model describes the local behaviour of the model. It is interpretable-by-design. The glass-box model is also called _local surrogate model_. LIME is an example of this approach.

Yet another approach is to investigate how changing the value of a single explanatory variable affects the response of the model for a particular instance. Ceteris-paribus profiles are very helpful in performing these _What-if analyses_.

### 6.1 Break-down plots

Break-down plots decompose a model’s prediction into contributions that are attributed to different explanatory variables.

We create a break-down plot for Johnny D's prediction obtained from the random forest model. For this we use the function `predict_parts()`. The function requires three arguments:

* `explainer`, an explainer object;
* `new_observation`, an observation to be explained;
* `type`, the method for calculation of variable attribution, for example `"break_down"`, `"break_down_interactions"` or `"shap"`.

```{r ex14, exercise = TRUE, exercise.eval = TRUE}
bd_rf <- predict_parts(explainer = titanic_rf_exp, 
                       new_observation = johnny_d, 
                       type = "break_down")
plot(bd_rf)
```

The first row in the break-down plot shows the overall mean value of predictions for the entire dataset. 

The next rows present the changes in the mean prediction when fixing values of subsequent explanatory variables. They are the contributions attributed to the explanatory variables, and can be positive (green) or negative (red).

The last row contains the prediction for the particular instance of interest. It is the sum of the overall mean value and the changes.

The random forest model predicts a higher probability of survival for Johnny D than Henry. How can we explain this difference? Create a second break-down plot for Henry and compare it to Johnny D's in order to answer this question.

```{r ex15, exercise = TRUE}

```
```{r ex15-solution}
plot(predict_parts(titanic_rf_exp, johnny_d, type = "break_down"), 
     title = "Break-down plot for Johnny D", min_max = c(0.2, 0.8))
plot(predict_parts(titanic_rf_exp, henry, type = "break_down"), 
     title = "Break-down plot for Henry", min_max = c(0.2, 0.8))
```

```{r q5}
question("According to these break-down plots, what is the main reason for the difference in predicted probability of survival?",
  answer("Johnny D's ticket was more expensive than Henry's. "),
  answer("Johnny D embarked in Southampton and Henry in Cherbourg."),
  answer("Johnny D is a child and Henry middle-aged.", TRUE),
  answer("Johnny D travels with his parents and Henry alone.")
)
```

These break-down plots only show the <u>additive</u> attributions. They may be misleading for models including interactions, which may well be the case for our random forest model. In the presence of interactions, the computed value of the attribution depends on the order of explanatory variables that are used in calculations. To address this issue, we can create [break-down plots for interactions](http://ema.drwhy.ai/iBreakDown.html) or use methods like SHAP or LIME.

### 6.2 SHAP

### 6.3 LIME

### 6.4 Ceteris-paribus profiles

## 7 Dataset level explanations
